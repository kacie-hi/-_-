import streamlit as st
import openai
import pytesseract
from PIL import Image

st.set_page_config(page_title='ê·¸ë˜ì„œâ€¦ ì–¼ë§ˆë©´ ë¼?', page_icon='ğŸ’¸', layout='centered')

# ìƒíƒœ ì €ì¥
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'api_key' not in st.session_state:
    st.session_state.api_key = ''
if 'name' not in st.session_state:
    st.session_state.name = ''
if 'dialogue' not in st.session_state:
    st.session_state.dialogue = ''
if 'result' not in st.session_state:
    st.session_state.result = None

# ìŠ¤íƒ€ì¼
st.markdown("""<style>
    .big-title { font-size: 36px; font-weight: 700; text-align: center; margin-bottom: 1rem; }
    .center { text-align: center; }
</style>""", unsafe_allow_html=True)

# Step 1: API í‚¤ ì…ë ¥
if st.session_state.step == 1:
    st.markdown('<div class="big-title">ê·¸ë˜ì„œ... ì–¼ë§ˆë©´ ë¼?</div>', unsafe_allow_html=True)
    st.write("GPTê°€ ë„ˆì™€ ìƒëŒ€ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ì„œ ì›ƒê¸°ê³  ì‚¬íšŒì ì¸ ì¶•ì˜ê¸ˆ ê¸ˆì•¡ì„ ì¶”ì²œí•´ì¤ë‹ˆë‹¤ ğŸ’Œ")
    st.session_state.api_key = st.text_input("ğŸ” OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", type="password")
    if st.button("ì¶•ì˜ê¸ˆ ê²°ì •í•˜ê¸°", disabled=not st.session_state.api_key.strip()):
        st.session_state.step = 2

# Step 2: ìƒëŒ€ ì •ë³´ & ëŒ€í™”
elif st.session_state.step == 2:
    st.markdown('<div class="big-title">ìƒëŒ€ë°© ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”</div>', unsafe_allow_html=True)
    st.session_state.name = st.text_input("ğŸ‘¤ ìƒëŒ€ë°© ì´ë¦„", placeholder="ì˜ˆ: ì§€í˜„")
    input_method = st.radio("ëŒ€í™” ì…ë ¥ ë°©ì‹", ["í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "ì¹´í†¡ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])
    
    if input_method == "í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥":
        st.session_state.dialogue = st.text_area("ğŸ’¬ ëŒ€í™” ë‚´ìš©", height=180,
            placeholder="ì˜ˆ: ë‚˜: ì•¼ ê²°í˜¼í•´? / ì¹œêµ¬: ã…‹ã…‹ ê°‘ìê¸° í•˜ê²Œ ëì–´ / ë‚˜: ëŒ€ë°• ì¶•í•˜í•´~")
    else:
        uploaded = st.file_uploader("ğŸ–¼ï¸ ëŒ€í™” ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"])
        if uploaded:
            img = Image.open(uploaded)
            st.image(img, caption="ì—…ë¡œë“œí•œ ëŒ€í™” ì´ë¯¸ì§€", use_column_width=True)
            st.session_state.dialogue = pytesseract.image_to_string(img, lang='kor')
            st.text_area("ğŸ“œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", value=st.session_state.dialogue, height=150)

    if st.button("ğŸ¯ ë¶„ì„ ì‹œì‘", disabled=not (st.session_state.api_key.strip() and st.session_state.dialogue.strip() and st.session_state.name.strip())):
        openai.api_key = st.session_state.api_key
        with st.spinner("AIê°€ ì‚¬íšŒì  ê±°ë¦¬ì™€ ê°ì •ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–ğŸ’­"):
            prompt = f"""
ë„ˆëŠ” ì¸ê°„ê´€ê³„ë¥¼ ë¶„ì„í•´ ì¶•ì˜ê¸ˆì„ ì¶”ì²œí•´ì£¼ëŠ” ìœ ì¾Œí•œ AIì•¼.
ìƒëŒ€ ì´ë¦„ì€ '{st.session_state.name}'ì´ê³ , ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë³´ê³ 
- ê°ì • / ì¹œë°€ë„ ë¶„ì„
- ì¶”ì²œ ì¶•ì˜ê¸ˆ ê¸ˆì•¡ ë˜ëŠ” ë¹ˆë´‰íˆ¬ ì˜µì…˜
- ë¹µ í„°ì§€ëŠ” ì›ƒê¸´ ì½”ë©˜íŠ¸
- ì‚¬íšŒìƒí™œ TMIê¹Œì§€ ë„£ì–´ì¤˜

ëŒ€í™”:
{st.session_state.dialogue}
"""

            try:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ì›ƒê¸°ê³  í˜„ì‹¤ì ì¸ ì¶•ì˜ê¸ˆ ë¶„ì„ê¸°ì•¼. ê²°ê³¼ëŠ” ì•„ì£¼ ì¬ë°Œê²Œ!"},
                        {"role": "user", "content": prompt}
                    ]
                )
                st.session_state.result = response.choices[0].message.content
                st.session_state.step = 3
            except Exception as e:
                st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")

# Step 3: ê²°ê³¼ í™”ë©´
elif st.session_state.step == 3:
    st.markdown('<div class="big-title">ğŸ’¸ AI ì¶•ì˜ê¸ˆ ë¶„ì„ ê²°ê³¼</div>', unsafe_allow_html=True)
    st.success(st.session_state.result)
    if st.button("ğŸ”„ ë‹¤ì‹œ í•˜ê¸°"):
        st.session_state.step = 1
        st.session_state.dialogue = ''
        st.session_state.name = ''
        st.session_state.result = None
